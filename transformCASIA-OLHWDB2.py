import argparse, cv2, os, timefrom utils.operation_file import mkdirfrom utils.read_ptts import read_ptts_to_img_linestart_time = time.time()parser = argparse.ArgumentParser(description='transformCASIA-OLHWDB2')parser.add_argument('--DEBUG',          help='不生成图片，用于调试',   type=str,   default=False)parser.add_argument('--OLHWDB2_ptts_path',  help='原始PTTS二进制文件',     type=str,   default=r"/home/datasets/textGroup/casia/source/CASIA-OLHWDB2")parser.add_argument('--save_path',          help='生成的图片要存储的路径,程序会自己创建文件夹',   type=str,   default=r'/home/datasets/textGroup/casia/temp-CASIA-OLHWDB-image')parser.add_argument('--SAVE_HEIGHT',        help='图片缩放到多高',         type=int,   default=128)parser.add_argument('--pen_thickness',      help='点集连成线的笔画粗细 ',   type=int,   default=2)parser.add_argument('--rectify_flag',       help='huber线性拟合矫正',      type=bool,  default=True)parser.add_argument('--fix_size',           help='是否将图片缩放成固定大小', type=bool,  default=False)parser.add_argument('--fix_w',              help='fix_size时要固定的宽度', type=int,   default=500)parser.add_argument('--core_region_flag',   help='是否使用核心区域估计算法',  type=bool,  default=False)parser.add_argument('--core_percentage',    help='核心区域占比',            type=int,   default=0.8)parser.add_argument('--bgColor_white',      help='图片背景颜色,默认黑色',    type=bool,  default=False)parser.add_argument('--padding_w',          help='左右两边各padding的像素',  type=int,   default=0)parser.add_argument('--padding_h',          help='上下两边各padding的像素',  type=int,   default=2)parser.add_argument('--PaSig_flag',         help='是否生成Path Signature',  type=bool,  default=False) # 这个功能暂时没用，请忽略parser.add_argument('--error_character_num',  type=int,   default=0)args = parser.parse_args()def get_root_dir_name(args):    if args.rectify_flag is False and args.core_region_flag is True:        raise NotImplementedError('请在数据倾斜矫正后再进行核心区域估计！')    resize_mode = str(args.SAVE_HEIGHT) + '_' + str(args.fix_w) + 'fix_' if args.fix_size else str(        args.SAVE_HEIGHT) + 'h_'    use_algorithm = 'basic'  # 图片除了正常resize（按高的比例缩放图片或者缩放到固定尺度），不做其他处理（比如倾斜矫正、核心区域估计）    if args.rectify_flag is True:        use_algorithm = 'rectify'  # huber线性拟合来进行倾斜矫正        if args.core_region_flag is True:            use_algorithm = 'rectify_coreRegion'  # 核心区域估计    mode = resize_mode + use_algorithm    root_dir_name = 'CASIA_OLHWDB2_' + mode    txt_suffix = '_' + mode + '.txt'    return root_dir_name, txt_suffixdef save_img_line_origin_shape(args, ptts_file_names, train_or_test, OLHWDB2_version):    # 获得最原始缩放后的图片，但对字符没有进行操作    file_lines = []    for ptts_file_path in ptts_file_names:        print('正在处理文件：', ptts_file_path, end='')        print('\ttime use : {} s'.format(round(time.time()-start_time, 2)))        img_line_list, label_list = read_ptts_to_img_line(args, ptts_file_path, train_or_test)  # 核心函数        for line_index, line_label in enumerate(label_list, start=1):            # linux 版本            txt_label_path_head = OLHWDB2_version + '/' + train_or_test + '/' + \                                  ptts_file_path.split('/')[-1].split('.')[0] + "-" + str(line_index) + '.png'            # windows 版本            # txt_label_path_head = OLHWDB2_version + '/' + train_or_test + '/' + \                                  # ptts_file_path.split('\\')[-1].split('.')[0] + "-" + str(line_index) + '.png'            line_save_path = os.path.join(img_save_path_root, txt_label_path_head)                        if args.DEBUG is False:                cv2.imencode('.png', img_line_list[line_index - 1])[1].tofile(line_save_path)   # 注释则不保存原图片                if args.PaSig_flag:                    pass            # print(txt_label_path_head + ' ' + line_label)            # print(line_save_path + ' ' + line_label)            file_lines.append(txt_label_path_head + ' ' + line_label + '\n')    return file_linesroot_dir_name, txt_suffix = get_root_dir_name(args)     # 根据用户设置生成的存储图片的一级目录 e.g.  XXX/CASIA_OLHWDB2_128h_basic/XXXif args.DEBUG:    img_save_path_root = os.path.join(args.save_path, 'temp_' + root_dir_name)else:    img_save_path_root = os.path.join(args.save_path, root_dir_name)print(img_save_path_root)OLHWDB2_versions_list = ['CASIA-OLHWDB2.0', 'CASIA-OLHWDB2.1', 'CASIA-OLHWDB2.2']# train_test = ['Train_Ptts']train_test = ['Train_Ptts', 'Test_Ptts']if os.path.exists(img_save_path_root):    txt_files = [files for files in os.listdir(img_save_path_root) if files.endswith('txt')]    for txt_file in txt_files:        if os.path.exists(txt_file):            os.remove(txt_file)            print('删除文件：'+ txt_file)    # 删除原有的txt文件##### For DEBUGall_char = ''line_num = 0#####for train_or_test in train_test:    for OLHWDB2_version in OLHWDB2_versions_list:        head_dir = os.path.join(args.OLHWDB2_ptts_path, OLHWDB2_version)  # e.g. head_dir = D:/data/CASIA-OLHWDB2/CASIA-OLHWDB2.0        train_or_test_dir = os.path.join(head_dir, train_or_test)        mkdir(os.path.join(img_save_path_root, OLHWDB2_version, train_or_test))        if args.PaSig_flag:            pass        txt_path = img_save_path_root + '/' + train_or_test + txt_suffix        with open(txt_path, 'a+', encoding='utf8') as f:            ptts_file_names = [os.path.join(train_or_test_dir, files) for files in sorted(os.listdir(train_or_test_dir)) if files.endswith('ptts')]            file_lines = save_img_line_origin_shape(args, ptts_file_names, train_or_test, OLHWDB2_version) # 核心            f.writelines(file_lines)            for file_line in file_lines:                all_char += file_line.split(' ')[1][:-1]            line_num += len(file_lines)print('time use : {} s'.format(round(time.time()-start_time, 2)))print('outlier char number：', args.error_character_num)print('class number：', len(set(all_char)))print('char number：', len(all_char))pass